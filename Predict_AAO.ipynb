{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from random import seed as rseed\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pre process\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, SGDRegressor, Lasso, Lars, ElasticNet\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/imputed_pre_and_manifest.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Number of visits of patients which were pre-manifest and became manifest </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = df['subjid'].isin(df.loc[df['hdcat'] == 2, 'subjid'].unique())\n",
    "man = df['subjid'].isin(df.loc[df['hdcat'] == 3, 'subjid'].unique())\n",
    "sel = df[(pre) & (man)]\n",
    "sel.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select training data (only diagnosed AAO, no estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown = df[df.hddiagn_est == 1].groupby('subjid').head(1) # Estimated or unknown\n",
    "known = df[df.hddiagn_est == 0].groupby('subjid').head(1) # Real HDdiagn\n",
    "\n",
    "print(unknown.shape, unknown.subjid.nunique(), known.shape, known.subjid.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.unique(known['caghigh'], return_counts=True)\n",
    "plt.bar(x, y)\n",
    "plt.xlabel('Larger CAG repeat size')\n",
    "plt.ylabel('Counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and refit Langbehn formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x, a, b, c):\n",
    "    return a + np.exp(c - (b * x))\n",
    "\n",
    "def refit_langbehn(subset):\n",
    "    a_langbehn = 21.54\n",
    "    b_langbehn = 0.1460\n",
    "    c_langbehn = 9.556\n",
    "    \n",
    "    x = subset['caghigh'].values\n",
    "    y = subset['hddiagn'].values\n",
    "\n",
    "    popt, pcov = curve_fit(func, x, y, p0=np.array([a_langbehn, b_langbehn, c_langbehn]))\n",
    "    print('a={:.3f}\\nb={:.3f}\\nc={:.3f}'.format(*popt))\n",
    "    return lambda x: func(x, *popt), popt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Original Langbehn formula </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langbehn = lambda x: 21.54 + np.exp( 9.556 - (0.1460 * x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "import matplotlib as mpl\n",
    "\n",
    "subset = df.groupby('subjid').first()[['caghigh', 'hddiagn']]\n",
    "subset = subset.loc[subset['caghigh'].between(40, 57)]\n",
    "x = np.sort(subset['caghigh'].unique())\n",
    "y = [langbehn(x_i) for x_i in x]\n",
    "\n",
    "sns.scatterplot(data=subset.sample(n=100, weights=compute_sample_weight('balanced', subset['caghigh']), random_state=42),\n",
    "                x='caghigh', y='hddiagn', ci=\"sd\", size=3, color='C1', legend=False)\n",
    "plt.plot(x, y, color='C2')\n",
    "\n",
    "plt.xticks(range(40, 57, 2))\n",
    "plt.xlabel('CAG Repeat')\n",
    "plt.ylabel('AAO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['caghigh', 'caglow', 'sex', 'parentagesx', 'momhd_0.0', 'momhd_1.0', 'dadhd_0.0', 'dadhd_1.0', 'fhx']\n",
    "df_filt = pd.read_csv('data/filtered_pre_and_manifest.csv')\n",
    "print('Missing percentages')\n",
    "df_filt.groupby('subjid').first()[cols].isna().sum() / df_filt['subjid'].nunique() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.all(df_filt.groupby('subjid').first()[['momhd_0.0', 'momhd_1.0']] == 0, axis=1).sum() / \n",
    "      df_filt['subjid'].nunique() * 100)\n",
    "print(np.all(df_filt.groupby('subjid').first()[['dadhd_0.0', 'dadhd_1.0']] == 0, axis=1).sum() / \n",
    "      df_filt['subjid'].nunique() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train ML and Evaluate all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred, outlier=False):\n",
    "    # max_ae = np.max(np.abs(y_true - y_pred))\n",
    "    if outlier:\n",
    "        u, o = np.mean(y_true), np.std(y_true)\n",
    "        mask = np.logical_or((y_true < u-o), (y_true > u+o))\n",
    "        y_true, y_pred = y_true[mask], y_pred[mask]\n",
    "    \n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    rmse = np.sqrt(np.mean(np.power(y_true - y_pred, 2)))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return [mae, rmse, r2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The models are trained on static variables which are the same for manifest and pre-manifest patients, namely\n",
    "# the larger and lower CAG repeatsize, gender, parent AAO, whether the mom and or dad had HD and whether \n",
    "# there was a family history for HD.\n",
    "def train(model, cag_range, fit, cols):\n",
    "    # Define seeds\n",
    "    seed_value = 42\n",
    "\n",
    "    # 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "    # 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "    rseed(seed_value)\n",
    "\n",
    "    # 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "    np.random.seed(seed_value)\n",
    "\n",
    "    # Select data\n",
    "    label = 'hddiagn'\n",
    "    subset = known.groupby('subjid').first().loc[:, [label] + cols]\n",
    "    subset = subset.loc[((subset['caghigh'] >= cag_range[0]) & (subset['caghigh'] <= cag_range[1]))]\n",
    "    print('Dropped {} samples'.format(subset.isnull().any(axis=1).sum()))\n",
    "    subset.dropna(inplace=True)\n",
    "    n = subset.shape[0]\n",
    "    print('{} samples left'.format(n)) \n",
    "    \n",
    "    # Get input and labels\n",
    "    input_data = subset[cols].values\n",
    "    targets = subset[label].values\n",
    "    \n",
    "    # Evaluation results\n",
    "    test_results = []\n",
    "    \n",
    "    # Fold labels and predictions\n",
    "    test_labels = []\n",
    "    test_predictions = []\n",
    "    \n",
    "    # Train and Evaluate\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=seed_value)\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(input_data, targets)):\n",
    "        # K-fold\n",
    "        X_train, X_valid = input_data[train_idx], input_data[test_idx]\n",
    "        y_train, y_valid = targets[train_idx], targets[test_idx]\n",
    "\n",
    "        # Scale\n",
    "        if fit:\n",
    "            model.fit(X_train, y_train)\n",
    "        \n",
    "        # prediction\n",
    "        try:\n",
    "            pred = model.predict(X_valid)\n",
    "        except:\n",
    "            pred = model(X_valid.reshape(-1))\n",
    "        \n",
    "        # Evaluate\n",
    "        test_results.append(evaluate(y_valid, pred))\n",
    "        \n",
    "    return pd.DataFrame(np.mean(test_results, axis=0).reshape(1, -1), columns=['MAE', 'RMSE', 'R2'])           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "\n",
    "def train_models(cag_min, cag_max):\n",
    "    print((known[(known['caghigh'] >=cag_min) & (known['caghigh'] <= cag_max)].copy()).shape)\n",
    "    langbehn_refitted, _ = refit_langbehn(known[(known['caghigh'] >=cag_min) & (known['caghigh'] <= cag_max)].copy())\n",
    "    langbehn_models = [langbehn, langbehn_refitted]\n",
    "    langbehn_names = ['Langbehn original', 'Langbehn refitted']\n",
    "    \n",
    "    models = langbehn_models + [LinearRegression(),\n",
    "                                RandomForestRegressor(random_state=42),\n",
    "                                CatBoostRegressor(verbose=0, random_seed=42),\n",
    "                                XGBRegressor(random_state=42),\n",
    "                                LGBMRegressor(random_state=42),\n",
    "                                MLPRegressor(max_iter=1000, random_state=42),\n",
    "                                LinearSVR(random_state=42, max_iter=50000),\n",
    "                                KNeighborsRegressor(5, weights='distance'),\n",
    "                               ]\n",
    "    \n",
    "    names = langbehn_names + ['Linear Regression',\n",
    "                              'Random Forest',\n",
    "                              'CatBoost',\n",
    "                              'XGBoost',\n",
    "                              'LGBM',\n",
    "                              'MLP',\n",
    "                              'Linear SVM',\n",
    "                              'KNN',\n",
    "                             ]\n",
    "    all_results = []\n",
    "    \n",
    "    # Eval\n",
    "    for name, mod in zip(names, models):\n",
    "        print('-' * 40)\n",
    "        print(name)\n",
    "        if 'Langbehn' in name:\n",
    "            results = train(mod, cag_range=(cag_min, cag_max), fit=False, cols=['caghigh'])\n",
    "        else:\n",
    "            results = train(mod, cag_range=(cag_min, cag_max), fit=True,\n",
    "                                              cols=['caghigh', 'caglow', 'sex', 'parentagesx',\n",
    "                                                    'momhd_0.0', 'momhd_1.0', 'dadhd_0.0', 'dadhd_1.0', 'fhx'])\n",
    "        results.index = [name]\n",
    "        all_results.append(list(results.reset_index().values.reshape(-1)))\n",
    "        print()\n",
    "    \n",
    "    # Save\n",
    "    summary = pd.DataFrame(all_results, columns=['Model', 'MAE', 'RMSE', 'R2'])\\\n",
    "                .set_index('Model')\\\n",
    "                .sort_values('R2', ascending=False)\n",
    "    summary.to_csv(os.path.join('tables', 'summary_AAO_{}-{}_models.csv'.format(cag_min, cag_max)), float_format='%.3f')\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Evaluate/fit models on CAG=41-56 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cag_min = 41\n",
    "cag_max = 56\n",
    "\n",
    "summary_small = train_models(cag_min, cag_max)\n",
    "summary_small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Evaluate/fit models on CAG=36-59 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cag_min = 36\n",
    "cag_max = 59\n",
    "\n",
    "summary_wide = train_models(cag_min, cag_max)\n",
    "summary_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_perc_improvement(old, new):\n",
    "    print((old - new).round(3))\n",
    "    print('{:5.2f}%'.format(np.mean((old - new) / old) * 100))\n",
    "\n",
    "calc_perc_improvement(summary_small.loc['Langbehn refitted', ['MAE', 'RMSE']], summary_small.loc['LGBM', ['MAE', 'RMSE']])\n",
    "calc_perc_improvement(summary_wide.loc['Langbehn refitted', ['MAE', 'RMSE']], summary_wide.loc['LGBM', ['MAE', 'RMSE']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31629b5f1f0da8e48893f7ca130076326da2a6d9b1f4e4c551ba1798dcd15a43"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
