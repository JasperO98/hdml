{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9e92fa7",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e43746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Cm for figures\n",
    "cm = 1/2.54"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7760e9c5",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2578c946",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('data', 'pre_and_manifest.csv'))\n",
    "df_filt = pd.read_csv(os.path.join('data', 'filtered_pre_and_manifest.csv'))\n",
    "df_imp = pd.read_csv(os.path.join('data', 'imputed_pre_and_manifest.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0cc045",
   "metadata": {},
   "source": [
    "# Dropped variables missing %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a68b67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_post = (df.isnull().sum() / df.shape[0]) * 100\n",
    "missing_post[list(set(df) - set(df_filt))].reset_index()\\\n",
    "                                          .rename(columns={'index': 'variable', 0: 'missing (%)'})\\\n",
    "                                          .sort_values('missing (%)', ascending=False)\\\n",
    "                                          .to_csv(os.path.join('additional_files', 'Additional file 1.csv'),\n",
    "                                                  index=False, float_format='%.2f'\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d95a721",
   "metadata": {},
   "source": [
    "# Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f680af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['score', 'mae', 'rmse']\n",
    "\n",
    "# Load results and get mean metrics for each variable + model\n",
    "train_results1 = pd.read_csv(os.path.join('tables', 'impute_train_1.csv'))\\\n",
    "                   .groupby(['variable', 'problem', 'model'])[metrics].mean().reset_index()\n",
    "test_results1 = pd.read_csv(os.path.join('tables', 'impute_test_1.csv'))\\\n",
    "                  .groupby(['variable', 'problem', 'model'])[metrics].mean().reset_index()\n",
    "\n",
    "train_results2 = pd.read_csv(os.path.join('tables', 'impute_train_2.csv'))\\\n",
    "                   .groupby(['variable', 'problem', 'model'])[metrics].mean().reset_index()\n",
    "test_results2 = pd.read_csv(os.path.join('tables', 'impute_test_2.csv'))\\\n",
    "                  .groupby(['variable', 'problem', 'model'])[metrics].mean().reset_index()\n",
    "\n",
    "best_models = pd.read_csv(os.path.join('tables', 'best_models.csv'))\n",
    "\n",
    "# Get best models from round1\n",
    "r1 = pd.merge(best_models.loc[best_models['round'] == 1], test_results1, on=['variable', 'model'], how='left')\n",
    "# Get best models from round2\n",
    "r2 = pd.merge(best_models.loc[best_models['round'] == 2], test_results2, on=['variable', 'model'], how='left')\n",
    "\n",
    "# Combine results with the given best models\n",
    "best_models_results = pd.concat([r1, r2]).sort_values('score').reset_index(drop=True)\n",
    "best_models_results = best_models_results.loc[~best_models_results['variable'].isin(['sbh1n', 'sbh3n', 'sbh4n'])]\n",
    "best_models_results['problem'] = best_models_results['problem'].replace({'reg': 'Regression',\n",
    "                                                                         'class': 'Classification',\n",
    "                                                                         'ordinal': 'Ordinal Regression',\n",
    "                                                                        })\n",
    "best_models_results['model'] = best_models_results['model'].replace({'knn': 'Knn',\n",
    "                                                                     'lin': 'Linear',\n",
    "                                                                     'tree': 'RF',\n",
    "                                                                    })\n",
    "best_models_results['model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4286ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorter(column):\n",
    "    reorder = ['RF', 'Linear', 'Knn']\n",
    "    # This also works:\n",
    "    # mapper = {name: order for order, name in enumerate(reorder)}\n",
    "    # return column.map(mapper)\n",
    "    cat = pd.Categorical(column, categories=reorder, ordered=True)\n",
    "    return pd.Series(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7bdc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "# sns.catplot(x='model', y='score', hue='round', col='problem', kind='swarm', data=best_models_results)\n",
    "# width : 0 -  8.5 - 17\n",
    "# height: 0 - 22.5\n",
    "chars = ['a)', 'b)', 'c)']\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(17*cm, 9*cm), sharey=False)\n",
    "for i, prob, ax in zip(range(3), best_models_results['problem'].unique(), axs):\n",
    "    subset = best_models_results.loc[best_models_results['problem']==prob]\\\n",
    "                                .sort_values(by=\"model\", key=sorter)\n",
    "    print('{} mean score: {:.3f}'.format(prob, subset.score.mean()))\n",
    "    sns.boxplot(x='model', y='score', hue='model', ax=ax, dodge=False, data=subset)\n",
    "    # sns.swarmplot(x='model', y='score', hue='model', ax=ax, dodge=False, data=subset)\n",
    "\n",
    "    if prob == 'Regression':\n",
    "        print('samples with R2 > 0.6', np.sum(subset['score'] > 0.6), '/', subset.shape[0])\n",
    "    elif prob == 'Ordinal Regression' or prob == 'Classification':\n",
    "        print('samples with F1 > 0.7', np.sum(subset['score'] > 0.7), '/', subset.shape[0])\n",
    "\n",
    "    # Plotting\n",
    "    ax.set_title(prob)\n",
    "    ax.legend().remove()\n",
    "    if i > 0:\n",
    "        ax.set_ylabel('F1 score')\n",
    "    else:\n",
    "        ax.set_ylabel('R2 score')\n",
    "    \n",
    "    ax.text(-0.2, 1.2, chars[i], transform=ax.transAxes, \n",
    "            size=10, weight='bold')\n",
    "    new_labels = []\n",
    "    for lab in ax.get_xticklabels():\n",
    "        txt = lab.get_text()\n",
    "        n = np.sum((best_models_results['problem']==prob) & (best_models_results['model']==txt))\n",
    "        new_labels.append('{}\\n(n={})'.format(txt, n))\n",
    "    ax.set_xticklabels(new_labels)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('output/figures/figure3.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f85f6c",
   "metadata": {},
   "source": [
    "# Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0705bd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def form(v):\n",
    "    if v in ['motscore', 'miscore', \n",
    "             'ocularh', 'ocularv', 'sacinith', 'sacinitv', 'sacvelh', 'sacvelv', 'dysarth', 'tongue', 'fingtapr',\n",
    "             'fingtapl', 'prosupr', 'prosupl', 'luria', 'rigarmr', 'rigarml', 'brady', 'dysttrnk', 'dystrue',\n",
    "             'dystlue', 'dystrle', 'dystlle', 'chorface', 'chorbol', 'chortrnk', 'chorrue', 'chorlue', 'chorrle',\n",
    "             'chorlle', 'gait', 'tandem', 'retropls', 'diagconf']:\n",
    "        return 'Motor'\n",
    "    elif v in ['tfcscore', 'occupatn', 'finances', 'chores', 'adl', 'carelevl']:\n",
    "        return 'TFC'\n",
    "    elif v in ['fascore', 'fiscore',\n",
    "               'emplusl', 'emplany', 'volunt', 'fafinan', 'grocery', 'cash', 'supchild', 'drive', 'housewrk', 'laundry',\n",
    "               'prepmeal', 'telephon', 'ownmeds', 'feedself', 'dress', 'bathe', 'pubtrans', 'walknbr', 'walkfall',\n",
    "               'walkhelp', 'comb', 'trnchair', 'bed', 'toilet', 'carehome', 'indepscl']:\n",
    "        return 'Function'\n",
    "    elif v in ['depscore', 'irascore', 'psyscore', 'aptscore', 'exfscore', 'pbas1sv', 'pbas1fr', 'pbas1wo', 'pbas2sv',\n",
    "               'pbas2fr', 'pbas2wo', 'pbas3sv', 'pbas3fr', 'pbas3wo', 'pbas4sv', 'pbas4fr', 'pbas4wo', 'pbas5sv',\n",
    "               'pbas5fr', 'pbas5wo', 'pbas6sv', 'pbas6fr', 'pbas6wo', 'pbas7sv', 'pbas7fr', 'pbas7wo', 'pbas8sv',\n",
    "               'pbas8fr', 'pbas8wo', 'pbas9sv', 'pbas9fr', 'pbas9wo', 'pbas10sv', 'pbas10sm__1', 'pbas10sm__2',\n",
    "               'pbas10sm__3', 'pbas10sm__4', 'pbas10sm__5', 'pbas10fr', 'pbas10wo', 'pbas11sv', 'pbas11fr', 'pbas11wo',\n",
    "               'pbainfo', 'pbahshd']:\n",
    "        return 'PBA-S'\n",
    "    elif v in ['hxalcab', 'hxtobab', 'hxtobcpd', 'hxtobyos', 'hxpacky', 'hxdrugab', 'hxmar', 'hxmarfrq', 'hxher',\n",
    "               'hxherfrq', 'hxcoc', 'hxcocfrq', 'hxclb', 'hxclbfrq', 'hxamp', 'hxampfrq', 'hxrit', 'hxritfrq', 'hxhal',\n",
    "               'hxhalfrq', 'hxinh', 'hxinhfrq', 'hxopi', 'hxopifrq', 'hxpak', 'hxpakfrq', 'hxbar', 'hxbarfrq', 'hxtrq',\n",
    "               'hxtrqfrq']:\n",
    "        return 'MHx'\n",
    "    elif v in ['height', 'weight', 'bmi', 'hdcat',\n",
    "               'alcab', 'alcunits', 'tobab', 'tobcpd', 'tobyos', 'packy', 'cafab', 'cafpd', 'drugab', 'mar', 'marfrq',\n",
    "               'her', 'herfrq', 'coc', 'cocfrq', 'clb', 'clbfrq', 'amp', 'ampfrq', 'rit', 'ritfrq', 'hal', 'halfrq',\n",
    "               'inh', 'inhfrq', 'opi', 'opifrq', 'pak', 'pakfrq', 'bar', 'barfrq', 'trq', 'trqfrq']:\n",
    "        return 'Var Items I'\n",
    "    elif v in ['updsc', 'maristat', 'res', 'isced', 'jobclas', 'jobpaid',\n",
    "               'rdcwk', 'rdcwkd', 'rdcwkhw', # Baseline\n",
    "               'emplnrsn', 'emplnrd', 'ssdb', 'rtrnwk', 'rtrddur']:\n",
    "        return 'Var Items II'\n",
    "    elif v in ['gen1', 'gen2', 'gen3', 'gen4', 'gen5', 'gen6', 'sdmt', 'sdmt1', 'sdmt2', 'sdmtnd', 'verfct', 'verfctd',\n",
    "               'verfct5', 'verfct6', 'verfct7', 'verfctnd', 'scnt', 'scnt1', 'scnt2', 'scnt3','scntnd', 'swrt', 'swrt1',\n",
    "               'swrt2', 'swrt3', 'swrtnd', 'sit', 'sit1', 'sit2', 'sit3', 'trl', 'trla1', 'trla2', 'trla3', 'trlb1',\n",
    "               'trlb2', 'trlb3', 'verflt', 'verflt05', 'verflt06', 'verflt07']:\n",
    "        return 'Cognitive'\n",
    "    elif v == 'mmsetotal':\n",
    "        return 'MMSE'\n",
    "    elif v in ['tug', 'tug1', 'scst', 'scst1']:\n",
    "        return 'Physiotherapy'\n",
    "    elif v in ['wpaiscr1', 'wpaiscr2', 'wpaiscr3', 'wpaiscr4']:\n",
    "        return 'WPAI-SHP'\n",
    "    elif v in ['scoring', 'pf', 'rp', 'bp', 'gh', 'vt', 'sf', 're', 'mh', 'pcs', 'mcs']:\n",
    "        return 'SF-12'\n",
    "    elif v in ['anxscore', 'hads_depscore', 'irrscore', 'outscore', 'inwscore']:\n",
    "        return 'HADS-SIS'\n",
    "    elif v in ['region', 'sex', 'race', 'handed', 'hxsid', 'dssage', 'dsplace', 'dsend', 'caghigh', 'caglow',\n",
    "               'momhd', 'momagesx', 'dadhd', 'dadagesx', 'fhx',\n",
    "               'ccmtr', 'ccmtrage', 'sxsubj', 'sxsubjm', 'sxs_m', 'sxs_c', 'sxs_p', 'sxs_o', 'sxfam',\n",
    "               'sxfamm', 'sxf_m', 'sxf_c', 'sxf_p', 'sxf_o', 'hddiagn', 'sxest', 'sxrater', 'sxestcfd', 'sxreas', 'sxgs',\n",
    "               'sxraterm', 'sxr_m', 'sxr_c', 'sxr_p', 'sxr_o', 'ccdep', 'ccdepage', 'ccirb', 'ccirbage',\n",
    "               'ccvab', 'ccvabage', 'ccapt', 'ccaptage', 'ccpob', 'ccpobage', 'ccpsy', 'ccpsyage', 'ccpsyfh', 'cccog',\n",
    "               'cccogage', 'xgwas', 'xbsp', 'xpheno', 'xmorpho', 'ximage']:\n",
    "        return 'Profile'\n",
    "    elif v in ['sid1', 'sid2', 'sid3', 'sid4', 'sid5', 'int1', 'int2', 'int3', 'int4', 'int5', 'int6', 'sbh1', 'sbh1n',\n",
    "               'sbh2', 'sbh3', 'sbh3n', 'sbh4', 'sbh4n', 'sbh5', 'sbh6', 'sbh7']:\n",
    "        return 'C-SSRS'\n",
    "    else:\n",
    "        return 'null'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9e9f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def completeness(preprocessed_data, original_data):\n",
    "    rows = preprocessed_data.shape[0]\n",
    "    rows2 = original_data.shape[0]\n",
    "        \n",
    "    preprocessed_data = preprocessed_data.isnull().sum().reset_index()\n",
    "    preprocessed_data.columns = ['variable', 'missing']\n",
    "    \n",
    "    original_data = original_data.isnull().sum().reset_index()\n",
    "    original_data.columns = ['variable', 'missing']\n",
    "\n",
    "    g1 = preprocessed_data['variable'].apply(lambda x: form(x) if form(x) !='null' else form(x.split('_')[0])) \n",
    "    preprocessed_data['group'] = g1.astype(str)\n",
    "    \n",
    "    g2 = original_data['variable'].apply(lambda x: form(x) if form(x) !='null' else form(x.split('_')[0])) \n",
    "    original_data['group'] = g2.astype(str)\n",
    "\n",
    "    preprocessed_data = preprocessed_data.groupby('group').missing.aggregate(['sum', 'count']) # .sort_values('mean')\n",
    "    original_data = original_data.groupby('group').missing.aggregate(['sum', 'count']) # .sort_values('mean')\n",
    "\n",
    "    \n",
    "    \n",
    "    cm = 1/2.54\n",
    "    plt.figure(figsize=(17*cm, 10*cm))\n",
    "    w = .3\n",
    "    plt.xticks(rotation=90)\n",
    "    forms = ['Profile', 'MHx', 'Var Items I', 'Var Items II', 'Motor', 'Function', 'TFC',\n",
    "             'Cognitive', 'MMSE', 'Physiotherapy', 'PBA-S', 'SF-12', 'HADS-SIS', 'WPAI-SHP', 'C-SSRS']\n",
    "    \n",
    "    for i, g in enumerate(forms):\n",
    "        if g in preprocessed_data.index:\n",
    "            p1 = plt.bar(x=i,\n",
    "                         height=100 * (1 - (preprocessed_data.loc[g,'sum'] / (rows * preprocessed_data.loc[g,'count']) )),\n",
    "                         # yerr=preprocessed_data.loc[g,'std'],\n",
    "                         width=w,\n",
    "                         color='C0',\n",
    "                         label='Pre-Processed',\n",
    "                        )\n",
    "        else:\n",
    "            p1 = plt.bar(x=i,\n",
    "                         height=0.0,\n",
    "                         #yerr=0.0,\n",
    "                         width=w,\n",
    "                         color='C0',\n",
    "                         label='Pre-Processed',\n",
    "                        )\n",
    "        if g in original_data.index:\n",
    "            p2 = plt.bar(x=i+w,\n",
    "                         height=100 * (1 - (original_data.loc[g,'sum'] / (rows2 * original_data.loc[g,'count']))),\n",
    "                         # yerr=original_data.loc[g,'std'],\n",
    "                         width=w,\n",
    "                         color='C1',\n",
    "                         label='Original',\n",
    "                        )\n",
    "        else:\n",
    "            p2 = plt.bar(x=i,\n",
    "                         height=0.0,\n",
    "                         #yerr=0.0,\n",
    "                         width=w,\n",
    "                         color='C0',\n",
    "                         label='Original',\n",
    "                        )\n",
    "    plt.legend([p1, p2], ['Pre-Processed', 'Original'], ncol=2,\n",
    "               bbox_to_anchor=(0., 1.02, 1., .102), loc=8, borderaxespad=0.)\n",
    "    plt.xticks([i + w*.5 for i in range(len(forms))], forms)\n",
    "    \n",
    "    plt.ylim(0, 105)\n",
    "    j = -.3\n",
    "\n",
    "    plt.ylabel('Completeness %')\n",
    "    plt.xlabel('Form')\n",
    "    plt.margins(0.01, 0.01)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig('figures/completeness.pdf', bbox_inches = 'tight', pad_inches = 0.05, dpi=1200)\n",
    "    plt.savefig('output/figures/figure2.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73a9bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "completeness(df_filt.copy(), df.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0885ed",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31629b5f1f0da8e48893f7ca130076326da2a6d9b1f4e4c551ba1798dcd15a43"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('hd_paper')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
