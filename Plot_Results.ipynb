{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9e92fa7",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e43746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Cm for figures\n",
    "cm = 1/2.54"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7760e9c5",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2578c946",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('data', 'pre_and_manifest.csv'))\n",
    "df_filt = pd.read_csv(os.path.join('data', 'filtered_pre_and_manifest.csv'))\n",
    "df_imp = pd.read_csv(os.path.join('data', 'imputed_pre_and_manifest.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba264a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.subjid.nunique(), df.shape,\n",
    "      df_filt.subjid.nunique(), df_filt.shape,\n",
    "      df_imp.subjid.nunique(), df_imp.shape\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df7cb49",
   "metadata": {},
   "source": [
    "# Compare Shapes after Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7190492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(df[['subjid', 'seq']].value_counts().values == 1), 'not unique combination of columns'\n",
    "raw_rows = df.merge(df_filt[['subjid', 'seq']], on=['subjid', 'seq'], how='inner')\n",
    "filt_rows = df_filt.merge(df[['subjid', 'seq']], on=['subjid', 'seq'], how='inner')\n",
    "print('Imputed missing values:', filt_rows.isnull().sum().sum() / raw_rows.isnull().sum().sum() * 100)\n",
    "print('Percentag missing values in raw:', raw_rows.isnull().sum().sum() / raw_rows.size * 100)\n",
    "print('Percentag missing values in filt:', filt_rows.isnull().sum().sum() / filt_rows.size * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b11a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Variables saved because of imputation:', df_imp.shape[1] - df_filt.dropna(axis=1).shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5226c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filt.isna().sum().replace(0, np.nan).dropna().sort_values(ascending=False) / df_filt.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0cc045",
   "metadata": {},
   "source": [
    "# Dropped variables missing %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a68b67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_post = (df.isnull().sum() / df.shape[0]) * 100\n",
    "missing_post = missing_post[list(set(df) - set(df_filt))].reset_index()\\\n",
    "                                                         .rename(columns={'index': 'variable', 0: 'missing (%)'})\\\n",
    "                                                         .sort_values('missing (%)', ascending=False)\n",
    "missing_post.to_csv(os.path.join('additional_files', 'Additional file 2.csv'), index=False, float_format='%.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d95a721",
   "metadata": {},
   "source": [
    "# Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f680af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['score', 'mae', 'rmse']\n",
    "\n",
    "# Load results and get mean metrics for each variable + model\n",
    "train_results1 = pd.read_csv(os.path.join('tables', 'impute_train_1.csv'))\\\n",
    "                   .groupby(['variable', 'problem', 'model'])[metrics].mean().reset_index()\n",
    "test_results1 = pd.read_csv(os.path.join('tables', 'impute_test_1.csv'))\\\n",
    "                  .groupby(['variable', 'problem', 'model'])[metrics].mean().reset_index()\n",
    "\n",
    "train_results2 = pd.read_csv(os.path.join('tables', 'impute_train_2.csv'))\\\n",
    "                   .groupby(['variable', 'problem', 'model'])[metrics].mean().reset_index()\n",
    "test_results2 = pd.read_csv(os.path.join('tables', 'impute_test_2.csv'))\\\n",
    "                  .groupby(['variable', 'problem', 'model'])[metrics].mean().reset_index()\n",
    "\n",
    "best_models = pd.read_csv(os.path.join('tables', 'best_models.csv'))\n",
    "\n",
    "# Get best models from round1\n",
    "r1 = pd.merge(best_models.loc[best_models['round'] == 1], test_results1, on=['variable', 'model'], how='left')\n",
    "# Get best models from round2\n",
    "r2 = pd.merge(best_models.loc[best_models['round'] == 2], test_results2, on=['variable', 'model'], how='left')\n",
    "\n",
    "# Combine results with the given best models\n",
    "best_models_results = pd.concat([r1, r2]).sort_values('score').reset_index(drop=True)\n",
    "best_models_results = best_models_results.loc[~best_models_results['variable'].isin(['sbh1n', 'sbh3n', 'sbh4n'])]\n",
    "best_models_results['problem'] = best_models_results['problem'].replace({'reg': 'Continuous',\n",
    "                                                                         'class': 'Categorical',\n",
    "                                                                         'ordinal': 'Ordinal',\n",
    "                                                                        })\n",
    "best_models_results['model'] = best_models_results['model'].replace({'knn': 'Knn',\n",
    "                                                                     'lin': 'Linear',\n",
    "                                                                     'tree': 'RF',\n",
    "                                                                    })\n",
    "best_models_results.sort_values('score', ascending=False)\\\n",
    "                   .drop(['mae', 'rmse'], axis=1)\\\n",
    "                   .round(2)\\\n",
    "                   .to_csv('additional_files/Additional file 8.csv', index=False)\n",
    "best_models_results['model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906b7b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_perc = (df_filt.isnull().sum() / df_filt.shape[0] * 100).reset_index()\\\n",
    "                                                                .rename(columns={'index': 'variable', 0: 'missing (%)'})\n",
    "score_missing = best_models_results.merge(missing_perc, on='variable')\\\n",
    "                                   .sort_values('score', ascending=False)\\\n",
    "                                   .drop(['mae', 'rmse'], axis=1)\\\n",
    "                                   .round(2)\\\n",
    "                                   .reset_index(drop=True)\n",
    "score_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05da1e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for prob in best_models_results['problem'].unique():\n",
    "    scores = best_models_results.loc[best_models_results['problem'] == prob, 'score']\n",
    "    print(prob, np.sum(scores > 0.75), '/', len(scores), round(np.sum(scores > 0.75) / len(scores) * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4286ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorter(column):\n",
    "    reorder = ['RF', 'Linear', 'Knn']\n",
    "    # This also works:\n",
    "    # mapper = {name: order for order, name in enumerate(reorder)}\n",
    "    # return column.map(mapper)\n",
    "    cat = pd.Categorical(column, categories=reorder, ordered=True)\n",
    "    return pd.Series(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7bdc87",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "# width : 0 -  8.5 - 17\n",
    "# height: 0 - 22.5\n",
    "chars = ['a)', 'b)', 'c)']\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(17*cm, 9*cm), sharey=True)\n",
    "for i, prob, ax in zip(range(3), best_models_results['problem'].unique(), axs):\n",
    "    subset = best_models_results.loc[best_models_results['problem']==prob]\\\n",
    "                                .sort_values(by=\"model\", key=sorter)\n",
    "    print('{} mean score: {:.3f}'.format(prob, subset.score.mean()))\n",
    "    \n",
    "    sns.boxplot(x='model', y='score', hue='model', ax=ax, dodge=False, data=subset,\n",
    "                showfliers=False)\n",
    "    sns.stripplot(x='model', y='score', hue='model', edgecolor='black', size=3.5,\n",
    "              ax=ax, dodge=False, data=subset, zorder=1, jitter=True, linewidth=.5)\n",
    "\n",
    "    if prob == 'Regression':\n",
    "        print('samples with R2 > 0.6', np.sum(subset['score'] > 0.6), '/', subset.shape[0])\n",
    "    elif prob == 'Ordinal Regression' or prob == 'Classification':\n",
    "        print('samples with F1 > 0.7', np.sum(subset['score'] > 0.7), '/', subset.shape[0])\n",
    "\n",
    "    # Plotting\n",
    "    ax.set_title(prob)\n",
    "    ax.legend().remove()\n",
    "    if i > 0:\n",
    "        ax.set_ylabel('F1 score')\n",
    "    else:\n",
    "        ax.set_ylabel('R2 score')\n",
    "\n",
    "    ax.text(-0.2, 1.2, chars[i], transform=ax.transAxes, \n",
    "            size=10, weight='bold')\n",
    "    new_labels = []\n",
    "    for lab in ax.get_xticklabels():\n",
    "        txt = lab.get_text()\n",
    "        n = np.sum((best_models_results['problem']==prob) & (best_models_results['model']==txt))\n",
    "        new_labels.append('{}\\n(n={})'.format(txt, n))\n",
    "    ax.set_xticklabels(new_labels)\n",
    "    for ax in axs.flatten():\n",
    "        ax.yaxis.set_tick_params(labelleft=True)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/figures/figure3.pdf', dpi=300, pad_inches=0, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f85f6c",
   "metadata": {},
   "source": [
    "# Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0705bd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def form(v):\n",
    "    if v in ['motscore', 'miscore', \n",
    "             'ocularh', 'ocularv', 'sacinith', 'sacinitv', 'sacvelh', 'sacvelv', 'dysarth', 'tongue', 'fingtapr',\n",
    "             'fingtapl', 'prosupr', 'prosupl', 'luria', 'rigarmr', 'rigarml', 'brady', 'dysttrnk', 'dystrue',\n",
    "             'dystlue', 'dystrle', 'dystlle', 'chorface', 'chorbol', 'chortrnk', 'chorrue', 'chorlue', 'chorrle',\n",
    "             'chorlle', 'gait', 'tandem', 'retropls', 'diagconf']:\n",
    "        return 'Motor'\n",
    "    elif v in ['tfcscore', 'occupatn', 'finances', 'chores', 'adl', 'carelevl']:\n",
    "        return 'TFC'\n",
    "    elif v in ['fascore', 'fiscore',\n",
    "               'emplusl', 'emplany', 'volunt', 'fafinan', 'grocery', 'cash', 'supchild', 'drive', 'housewrk', 'laundry',\n",
    "               'prepmeal', 'telephon', 'ownmeds', 'feedself', 'dress', 'bathe', 'pubtrans', 'walknbr', 'walkfall',\n",
    "               'walkhelp', 'comb', 'trnchair', 'bed', 'toilet', 'carehome', 'indepscl']:\n",
    "        return 'Function'\n",
    "    elif v in ['depscore', 'irascore', 'psyscore', 'aptscore', 'exfscore', 'pbas1sv', 'pbas1fr', 'pbas1wo', 'pbas2sv',\n",
    "               'pbas2fr', 'pbas2wo', 'pbas3sv', 'pbas3fr', 'pbas3wo', 'pbas4sv', 'pbas4fr', 'pbas4wo', 'pbas5sv',\n",
    "               'pbas5fr', 'pbas5wo', 'pbas6sv', 'pbas6fr', 'pbas6wo', 'pbas7sv', 'pbas7fr', 'pbas7wo', 'pbas8sv',\n",
    "               'pbas8fr', 'pbas8wo', 'pbas9sv', 'pbas9fr', 'pbas9wo', 'pbas10sv', 'pbas10sm__1', 'pbas10sm__2',\n",
    "               'pbas10sm__3', 'pbas10sm__4', 'pbas10sm__5', 'pbas10fr', 'pbas10wo', 'pbas11sv', 'pbas11fr', 'pbas11wo',\n",
    "               'pbainfo', 'pbahshd']:\n",
    "        return 'PBA-S'\n",
    "    elif v in ['hxalcab', 'hxtobab', 'hxtobcpd', 'hxtobyos', 'hxpacky', 'hxdrugab', 'hxmar', 'hxmarfrq', 'hxher',\n",
    "               'hxherfrq', 'hxcoc', 'hxcocfrq', 'hxclb', 'hxclbfrq', 'hxamp', 'hxampfrq', 'hxrit', 'hxritfrq', 'hxhal',\n",
    "               'hxhalfrq', 'hxinh', 'hxinhfrq', 'hxopi', 'hxopifrq', 'hxpak', 'hxpakfrq', 'hxbar', 'hxbarfrq', 'hxtrq',\n",
    "               'hxtrqfrq']:\n",
    "        return 'MHx'\n",
    "    elif v in ['height', 'weight', 'bmi', 'hdcat',\n",
    "               'alcab', 'alcunits', 'tobab', 'tobcpd', 'tobyos', 'packy', 'cafab', 'cafpd', 'drugab', 'mar', 'marfrq',\n",
    "               'her', 'herfrq', 'coc', 'cocfrq', 'clb', 'clbfrq', 'amp', 'ampfrq', 'rit', 'ritfrq', 'hal', 'halfrq',\n",
    "               'inh', 'inhfrq', 'opi', 'opifrq', 'pak', 'pakfrq', 'bar', 'barfrq', 'trq', 'trqfrq']:\n",
    "        return 'Var Items I'\n",
    "    elif v in ['updsc', 'maristat', 'res', 'isced', 'jobclas', 'jobpaid',\n",
    "               'rdcwk', 'rdcwkd', 'rdcwkhw', # Baseline\n",
    "               'emplnrsn', 'emplnrd', 'ssdb', 'rtrnwk', 'rtrddur']:\n",
    "        return 'Var Items II'\n",
    "    elif v in ['gen1', 'gen2', 'gen3', 'gen4', 'gen5', 'gen6', 'sdmt', 'sdmt1', 'sdmt2', 'sdmtnd', 'verfct', 'verfctd',\n",
    "               'verfct5', 'verfct6', 'verfct7', 'verfctnd', 'scnt', 'scnt1', 'scnt2', 'scnt3','scntnd', 'swrt', 'swrt1',\n",
    "               'swrt2', 'swrt3', 'swrtnd', 'sit', 'sit1', 'sit2', 'sit3', 'trl', 'trla1', 'trla2', 'trla3', 'trlb1',\n",
    "               'trlb2', 'trlb3', 'verflt', 'verflt05', 'verflt06', 'verflt07']:\n",
    "        return 'Cognitive'\n",
    "    elif v == 'mmsetotal':\n",
    "        return 'MMSE'\n",
    "    elif v in ['tug', 'tug1', 'scst', 'scst1']:\n",
    "        return 'Physiotherapy'\n",
    "    elif v in ['wpaiscr1', 'wpaiscr2', 'wpaiscr3', 'wpaiscr4']:\n",
    "        return 'WPAI-SHP'\n",
    "    elif v in ['scoring', 'pf', 'rp', 'bp', 'gh', 'vt', 'sf', 're', 'mh', 'pcs', 'mcs']:\n",
    "        return 'SF-12'\n",
    "    elif v in ['anxscore', 'hads_depscore', 'irrscore', 'outscore', 'inwscore']:\n",
    "        return 'HADS-SIS'\n",
    "    elif v in ['region', 'sex', 'race', 'handed', 'hxsid', 'dssage', 'dsplace', 'dsend', 'caghigh', 'caglow',\n",
    "               'momhd', 'momagesx', 'dadhd', 'dadagesx', 'fhx',\n",
    "               'ccmtr', 'ccmtrage', 'sxsubj', 'sxsubjm', 'sxs_m', 'sxs_c', 'sxs_p', 'sxs_o', 'sxfam',\n",
    "               'sxfamm', 'sxf_m', 'sxf_c', 'sxf_p', 'sxf_o', 'hddiagn', 'sxest', 'sxrater', 'sxestcfd', 'sxreas', 'sxgs',\n",
    "               'sxraterm', 'sxr_m', 'sxr_c', 'sxr_p', 'sxr_o', 'ccdep', 'ccdepage', 'ccirb', 'ccirbage',\n",
    "               'ccvab', 'ccvabage', 'ccapt', 'ccaptage', 'ccpob', 'ccpobage', 'ccpsy', 'ccpsyage', 'ccpsyfh', 'cccog',\n",
    "               'cccogage', 'xgwas', 'xbsp', 'xpheno', 'xmorpho', 'ximage']:\n",
    "        return 'Profile'\n",
    "    elif v in ['sid1', 'sid2', 'sid3', 'sid4', 'sid5', 'int1', 'int2', 'int3', 'int4', 'int5', 'int6', 'sbh1', 'sbh1n',\n",
    "               'sbh2', 'sbh3', 'sbh3n', 'sbh4', 'sbh4n', 'sbh5', 'sbh6', 'sbh7']:\n",
    "        return 'C-SSRS'\n",
    "    else:\n",
    "        return 'null'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9e9f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def completeness(preprocessed_data, original_data):\n",
    "    rows = preprocessed_data.shape[0]\n",
    "    rows2 = original_data.shape[0]\n",
    "        \n",
    "    preprocessed_data = preprocessed_data.isnull().sum().reset_index()\n",
    "    preprocessed_data.columns = ['variable', 'missing']\n",
    "    \n",
    "    original_data = original_data.isnull().sum().reset_index()\n",
    "    original_data.columns = ['variable', 'missing']\n",
    "\n",
    "    g1 = preprocessed_data['variable'].apply(lambda x: form(x) if form(x) !='null' else form(x.split('_')[0])) \n",
    "    preprocessed_data['group'] = g1.astype(str)\n",
    "    \n",
    "    g2 = original_data['variable'].apply(lambda x: form(x) if form(x) !='null' else form(x.split('_')[0])) \n",
    "    original_data['group'] = g2.astype(str)\n",
    "\n",
    "    preprocessed_data = preprocessed_data.groupby('group').missing.aggregate(['sum', 'count']) # .sort_values('mean')\n",
    "    original_data = original_data.groupby('group').missing.aggregate(['sum', 'count']) # .sort_values('mean') \n",
    "    \n",
    "    cm = 1/2.54\n",
    "    plt.figure(figsize=(17*cm, 10*cm))\n",
    "    w = .3\n",
    "    plt.xticks(rotation=90)\n",
    "    forms = ['Profile', 'MHx', 'Var Items I', 'Var Items II', 'Motor', 'Function', 'TFC',\n",
    "             'Cognitive', 'MMSE', 'Physiotherapy', 'PBA-S', 'SF-12', 'HADS-SIS', 'WPAI-SHP', 'C-SSRS']\n",
    "    \n",
    "    for i, g in enumerate(forms):\n",
    "        if g in preprocessed_data.index:\n",
    "            p1 = plt.bar(x=i+w,\n",
    "                         height=100 * (1 - (preprocessed_data.loc[g,'sum'] / (rows * preprocessed_data.loc[g,'count']) )),\n",
    "                         alpha=.9,\n",
    "                         width=w,\n",
    "                         color='C2',\n",
    "                         edgecolor='black',\n",
    "                         linewidth=.5,\n",
    "                         label='Pre-Processed',\n",
    "                        )\n",
    "        else:\n",
    "            p1 = plt.bar(x=i+w,\n",
    "                         height=0.0,\n",
    "                         alpha=.9,\n",
    "                         width=w,\n",
    "                         color='C2',\n",
    "                         edgecolor='black',\n",
    "                         linewidth=.5,\n",
    "                         label='Pre-Processed',\n",
    "                        )\n",
    "        if g in original_data.index:\n",
    "            p2 = plt.bar(x=i,\n",
    "                         height=100 * (1 - (original_data.loc[g,'sum'] / (rows2 * original_data.loc[g,'count']))),\n",
    "                         alpha=.9,\n",
    "                         width=w,\n",
    "                         color='C0',\n",
    "                         edgecolor='black',\n",
    "                         linewidth=.5,\n",
    "                         label='Original',\n",
    "                        )\n",
    "        else:\n",
    "            p2 = plt.bar(x=i,\n",
    "                         height=0.0,\n",
    "                         alpha=.9,\n",
    "                         width=w,\n",
    "                         color='C0',\n",
    "                         edgecolor='black',\n",
    "                         linewidth=.5,\n",
    "                         label='Original',\n",
    "                        )\n",
    "    plt.legend([p2, p1], ['Original', 'Pre-Processed'], ncol=2,\n",
    "                bbox_to_anchor=(0., 1.02, 1., .102), loc=8, borderaxespad=0.)\n",
    "    plt.xticks([i + w*.5 for i in range(len(forms))], forms)\n",
    "    \n",
    "    plt.ylim(0, 105)\n",
    "    j = -.3\n",
    "\n",
    "    plt.ylabel('Completeness %')\n",
    "    plt.xlabel('Form')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('output/figures/figure2.pdf', dpi=300, bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73a9bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "completeness(df_filt.copy(), df.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0885ed",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ed85de37ebc6aa7d5256bd6e2a558a30ac7413d85458a0b33d66c485fa854fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
